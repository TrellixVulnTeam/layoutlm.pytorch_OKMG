{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import layoutlm\n",
    "from layoutlm.data import FunsdDataset\n",
    "\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForTokenClassification,\n",
    "    BertTokenizer,\n",
    "    RobertaConfig,\n",
    "    RobertaForTokenClassification,\n",
    "    RobertaTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_bert.BertTokenizer"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.Namespace()\n",
    "parser.data_dir = 'data/funsd'\n",
    "parser.model_type = 'layoutlm'\n",
    "parser.model_name_or_path = \"layoutlm-base-uncased\"\n",
    "parser.do_lower_case = True\n",
    "parser.max_seq_length = 512\n",
    "parser.num_train_epochs = 100.0\n",
    "parser.logging_steps = 10\n",
    "parser.save_steps = -1\n",
    "parser.output_dir = None\n",
    "parser.labels = \"data/funsd/labels.txt\"\n",
    "parser.per_gpu_train_batch_size = 16\n",
    "parser.per_gpu_eval_batch_size = 16\n",
    "parser.local_rank = -1\n",
    "parser.overwrite_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        labels = f.read().splitlines()\n",
    "    if \"O\" not in labels:\n",
    "        labels = [\"O\"] + labels\n",
    "    return labels\n",
    "\n",
    "labels = get_labels(parser.labels)\n",
    "# labels\n",
    "pad_token_label_id = nn.CrossEntropyLoss().ignore_index\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[unused9]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FunsdDataset(parser, tokenizer=tokenizer, labels=labels, pad_token_label_id=pad_token_label_id, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python run_seq_labeling.py  --data_dir data \\\n",
    "#                             --model_type layoutlm \\\n",
    "#                             --model_name_or_path path/to/pretrained/model/directory \\\n",
    "#                             --do_lower_case \\\n",
    "#                             --max_seq_length 512 \\\n",
    "#                             --do_train \\\n",
    "#                             --num_train_epochs 100.0 \\\n",
    "#                             --logging_steps 10 \\\n",
    "#                             --save_steps -1 \\\n",
    "#                             --output_dir path/to/output/directory \\\n",
    "#                             --labels data/labels.txt \\\n",
    "#                             --per_gpu_train_batch_size 16 \\\n",
    "#                             --per_gpu_eval_batch_size 16 \\\n",
    "#                             --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, input_masks, segment_ids, label_ids, bboxes  = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 100\n",
    "input_ids[idx], input_masks[idx], segment_ids[idx], label_ids[idx], bboxes[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  6904,  2595,  1024,  3058,  1024,  2013,  1024,  3715,  5963,\n",
       "         1024,  7799,  2194,  6904,  2595,  2053,  1012,  7928,  2053,  1024,\n",
       "         2171,  1024,  2748, 13964,  1024, 19843, 26224, 26976,  2683,  2581,\n",
       "         2620, 10180,  1004, 13137,  2078,  6904,  2595,  3104,  7123,  5003,\n",
       "         4328,  3979,  2609,  1010,  2456,  2034,  2586,  3361,  2415,  1010,\n",
       "         3263,  2148, 20377,  3540,  9654,  8459,  5631,  1010,  3516, 27533,\n",
       "        21486,  1006, 20405,  1007,  4278,  1020,  5757,  3263,  2380,  3927,\n",
       "         2047,  7677,  8024,  6396, 28707,  2575,  4601,  2683,  2509, 18164,\n",
       "        28135,  1011, 25535,  2692,  4278,  1048,  1012,  2395,  1050,  9378,\n",
       "         9328,  2669,  5887,  2456,  2629,  8698,  2475, 16798,  4261,  2487,\n",
       "        24902,  2692,  3486,  2225, 11333,  9102,  3190,  1012,  6335, 24622,\n",
       "        24096, 21036,  1011,  5388,  2620, 23712,  2692,  2538,  3927,  5125,\n",
       "         9395,  4293,  3000,  1010,  2605,  3943,  1011,  5187,  4185,  5786,\n",
       "         6445,  6904,  2595,  2193,  1024, 20405,  4278,  1011, 19827,  2581,\n",
       "         4901,  6583,  8024,  2080,  2184,  1013,  2410,  1013,  5585,  4601,\n",
       "         2575,  2475,  1013, 17696,  3531,  8116,  2004,  2574,  2825,  2000,\n",
       "         1024,  2198, 14163, 16502,  8004,  7296,  2210,  5170,  6384,  5170,\n",
       "         6384,  6205,  2581,  1011,  5764,  2509,  1011,  5401,  2683,  2575,\n",
       "         6205,  2581,  1011,  5764,  2509,  5354,  2581,  2683,  6205,  2581,\n",
       "         1011,  5764,  2509, 20405,  2575,  3042,  2053,  1012,  2561,  2193,\n",
       "         1997,  5530,  2164,  2023,  3931,  1024,  2065,  2017,  2079,  2025,\n",
       "         4374,  2035,  1996,  5530,  1010,  3531,  2655,  2256,  6904,  2595,\n",
       "         6872,  2004,  2574,  2004,  2825,  4067,  2017,  1012, 21036,  1011,\n",
       "         4583,  2620,  1011,  5354, 18139,  1996,  2592,  4838,  1999,  2023,\n",
       "         6904,  6169, 27605,  2571,  4471,  2003,  2012,  4263,  9407, 21598,\n",
       "         1998, 18777,  2592,  3832,  2069,  2005,  1996,  2224,  1997,  1996,\n",
       "         3265,  2030,  9178,  2315,  2682,  1012,  2065,  1996,  8068,  1997,\n",
       "         2023,  4471,  2003,  2025,  1996,  3832,  7799,  1010,  2030,  1996,\n",
       "         7904,  2030,  4005,  3625,  2000,  8116,  2009,  2000,  1996,  3832,\n",
       "         7799,  1010,  2017,  2024,  2182,  3762, 19488,  2008,  2151, 28170,\n",
       "         1010,  4353,  2030, 24731,  2023,  4807,  9975, 10890,  1012,  2065,\n",
       "         2017,  2031,  2363,  2023,  4807,  1999,  7561,  1010,  3531,  3202,\n",
       "         2025,  8757,  2149,  2011,  7026,  1010,  1998,  2709,  1996,  2434,\n",
       "         4471,  2000,  2149,  2012,  1996,  2682,  4769,  3081,  1996,  1057,\n",
       "         1012,  1055,  1012, 10690,  2326,  1012,  4067,  2017,  1012,  6872,\n",
       "        20381,  1024,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# segment_ids\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  6904,  2595,  1024,  3058,  1024,  2013,  1024,  3715,  5963,\n",
       "         1024,  7799,  2194,  6904,  2595,  2053,  1012,  7928,  2053,  1024,\n",
       "         2171,  1024,  2748, 13964,  1024, 19843, 26224, 26976,  2683,  2581,\n",
       "         2620, 10180,  1004, 13137,  2078,  6904,  2595,  3104,  7123,  5003,\n",
       "         4328,  3979,  2609,  1010,  2456,  2034,  2586,  3361,  2415,  1010,\n",
       "         3263,  2148, 20377,  3540,  9654,  8459,  5631,  1010,  3516, 27533,\n",
       "        21486,  1006, 20405,  1007,  4278,  1020,  5757,  3263,  2380,  3927,\n",
       "         2047,  7677,  8024,  6396, 28707,  2575,  4601,  2683,  2509, 18164,\n",
       "        28135,  1011, 25535,  2692,  4278,  1048,  1012,  2395,  1050,  9378,\n",
       "         9328,  2669,  5887,  2456,  2629,  8698,  2475, 16798,  4261,  2487,\n",
       "        24902,  2692,  3486,  2225, 11333,  9102,  3190,  1012,  6335, 24622,\n",
       "        24096, 21036,  1011,  5388,  2620, 23712,  2692,  2538,  3927,  5125,\n",
       "         9395,  4293,  3000,  1010,  2605,  3943,  1011,  5187,  4185,  5786,\n",
       "         6445,  6904,  2595,  2193,  1024, 20405,  4278,  1011, 19827,  2581,\n",
       "         4901,  6583,  8024,  2080,  2184,  1013,  2410,  1013,  5585,  4601,\n",
       "         2575,  2475,  1013, 17696,  3531,  8116,  2004,  2574,  2825,  2000,\n",
       "         1024,  2198, 14163, 16502,  8004,  7296,  2210,  5170,  6384,  5170,\n",
       "         6384,  6205,  2581,  1011,  5764,  2509,  1011,  5401,  2683,  2575,\n",
       "         6205,  2581,  1011,  5764,  2509,  5354,  2581,  2683,  6205,  2581,\n",
       "         1011,  5764,  2509, 20405,  2575,  3042,  2053,  1012,  2561,  2193,\n",
       "         1997,  5530,  2164,  2023,  3931,  1024,  2065,  2017,  2079,  2025,\n",
       "         4374,  2035,  1996,  5530,  1010,  3531,  2655,  2256,  6904,  2595,\n",
       "         6872,  2004,  2574,  2004,  2825,  4067,  2017,  1012, 21036,  1011,\n",
       "         4583,  2620,  1011,  5354, 18139,  1996,  2592,  4838,  1999,  2023,\n",
       "         6904,  6169, 27605,  2571,  4471,  2003,  2012,  4263,  9407, 21598,\n",
       "         1998, 18777,  2592,  3832,  2069,  2005,  1996,  2224,  1997,  1996,\n",
       "         3265,  2030,  9178,  2315,  2682,  1012,  2065,  1996,  8068,  1997,\n",
       "         2023,  4471,  2003,  2025,  1996,  3832,  7799,  1010,  2030,  1996,\n",
       "         7904,  2030,  4005,  3625,  2000,  8116,  2009,  2000,  1996,  3832,\n",
       "         7799,  1010,  2017,  2024,  2182,  3762, 19488,  2008,  2151, 28170,\n",
       "         1010,  4353,  2030, 24731,  2023,  4807,  9975, 10890,  1012,  2065,\n",
       "         2017,  2031,  2363,  2023,  4807,  1999,  7561,  1010,  3531,  3202,\n",
       "         2025,  8757,  2149,  2011,  7026,  1010,  1998,  2709,  1996,  2434,\n",
       "         4471,  2000,  2149,  2012,  1996,  2682,  4769,  3081,  1996,  1057,\n",
       "         1012,  1055,  1012, 10690,  2326,  1012,  4067,  2017,  1012,  6872,\n",
       "        20381,  1024,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] - [0, 0, 0, 0]\n",
      "fa - [127, 177, 156, 192]\n",
      "##x - [127, 177, 156, 192]\n",
      ": - [127, 177, 156, 192]\n",
      "date - [99, 337, 153, 351]\n",
      ": - [99, 337, 153, 351]\n",
      "from - [99, 286, 155, 301]\n",
      ": - [99, 286, 155, 301]\n",
      "charge - [606, 288, 721, 305]\n",
      "##back - [606, 288, 721, 305]\n",
      ": - [606, 288, 721, 305]\n",
      "recipient - [140, 404, 233, 418]\n",
      "company - [311, 402, 395, 419]\n",
      "fa - [527, 404, 563, 418]\n",
      "##x - [527, 404, 563, 418]\n",
      "no - [564, 405, 598, 418]\n",
      ". - [564, 405, 598, 418]\n",
      "comments - [102, 532, 194, 546]\n",
      "no - [713, 934, 745, 952]\n",
      ": - [713, 934, 745, 952]\n",
      "name - [342, 936, 396, 953]\n",
      ": - [342, 936, 396, 953]\n",
      "yes - [259, 936, 293, 951]\n",
      "confirmation - [139, 937, 255, 952]\n",
      ": - [139, 937, 255, 952]\n",
      "207 - [909, 831, 936, 926]\n",
      "##49 - [909, 831, 936, 926]\n",
      "##56 - [909, 831, 936, 926]\n",
      "##9 - [909, 831, 936, 926]\n",
      "##7 - [909, 831, 936, 926]\n",
      "##8 - [909, 831, 936, 926]\n",
      "winston - [102, 95, 367, 151]\n",
      "& - [374, 95, 419, 148]\n",
      "straw - [424, 99, 647, 149]\n",
      "##n - [424, 99, 647, 149]\n",
      "fa - [681, 137, 717, 155]\n",
      "##x - [681, 137, 717, 155]\n",
      "cover - [720, 137, 767, 155]\n",
      "sheet - [769, 137, 814, 158]\n",
      "ma - [127, 158, 160, 166]\n",
      "##mi - [127, 158, 160, 166]\n",
      "trial - [163, 156, 196, 167]\n",
      "site - [200, 156, 229, 167]\n",
      ", - [200, 156, 229, 167]\n",
      "2000 - [234, 155, 279, 165]\n",
      "first - [285, 155, 320, 166]\n",
      "union - [322, 155, 359, 166]\n",
      "financial - [360, 156, 423, 169]\n",
      "center - [425, 158, 477, 169]\n",
      ", - [425, 158, 477, 169]\n",
      "200 - [484, 158, 513, 169]\n",
      "south - [517, 156, 558, 167]\n",
      "bis - [561, 158, 618, 168]\n",
      "##ca - [561, 158, 618, 168]\n",
      "##yne - [561, 158, 618, 168]\n",
      "boulevard - [125, 169, 200, 179]\n",
      "miami - [206, 170, 245, 178]\n",
      ", - [206, 170, 245, 178]\n",
      "florida - [251, 168, 302, 181]\n",
      "331 - [314, 168, 366, 181]\n",
      "##31 - [314, 168, 366, 181]\n",
      "( - [167, 179, 212, 192]\n",
      "305 - [167, 179, 212, 192]\n",
      ") - [167, 179, 212, 192]\n",
      "400 - [214, 179, 248, 192]\n",
      "6 - [250, 180, 263, 190]\n",
      "06 - [269, 180, 298, 190]\n",
      "200 - [103, 207, 127, 217]\n",
      "park - [129, 205, 157, 216]\n",
      "avenue - [161, 208, 198, 216]\n",
      "new - [102, 218, 156, 226]\n",
      "##yo - [102, 218, 156, 226]\n",
      "##rk - [102, 218, 156, 226]\n",
      "ny - [159, 218, 176, 225]\n",
      "1016 - [181, 218, 222, 226]\n",
      "##6 - [181, 218, 222, 226]\n",
      "41 - [224, 216, 261, 226]\n",
      "##9 - [224, 216, 261, 226]\n",
      "##3 - [224, 216, 261, 226]\n",
      "212 - [106, 228, 129, 236]\n",
      "294 - [129, 228, 196, 238]\n",
      "- - [129, 228, 196, 238]\n",
      "670 - [129, 228, 196, 238]\n",
      "##0 - [129, 228, 196, 238]\n",
      "400 - [299, 208, 327, 216]\n",
      "l - [330, 208, 339, 216]\n",
      ". - [330, 208, 339, 216]\n",
      "street - [339, 208, 377, 215]\n",
      "n - [379, 208, 392, 216]\n",
      "wash - [290, 218, 352, 225]\n",
      "##wing - [290, 218, 352, 225]\n",
      "##ton - [290, 218, 352, 225]\n",
      "dc - [359, 218, 374, 226]\n",
      "2000 - [379, 219, 420, 226]\n",
      "##5 - [379, 219, 420, 226]\n",
      "350 - [421, 218, 458, 225]\n",
      "##2 - [421, 218, 458, 225]\n",
      "202 - [293, 228, 316, 236]\n",
      "37 - [316, 226, 344, 236]\n",
      "##1 - [316, 226, 344, 236]\n",
      "570 - [346, 228, 383, 236]\n",
      "##0 - [346, 228, 383, 236]\n",
      "35 - [480, 209, 497, 216]\n",
      "west - [500, 208, 523, 216]\n",
      "wa - [527, 208, 563, 218]\n",
      "##cker - [527, 208, 563, 218]\n",
      "chicago - [480, 219, 522, 227]\n",
      ". - [480, 219, 522, 227]\n",
      "il - [523, 219, 537, 226]\n",
      "306 - [545, 219, 586, 227]\n",
      "##01 - [545, 219, 586, 227]\n",
      "312 - [477, 229, 509, 239]\n",
      "- - [477, 229, 509, 239]\n",
      "58 - [507, 229, 535, 239]\n",
      "##8 - [507, 229, 535, 239]\n",
      "580 - [537, 229, 568, 239]\n",
      "##0 - [537, 229, 568, 239]\n",
      "21 - [663, 209, 680, 217]\n",
      "avenue - [685, 209, 722, 219]\n",
      "victor - [724, 209, 757, 217]\n",
      "hugo - [759, 209, 787, 217]\n",
      "75 - [667, 219, 687, 227]\n",
      "paris - [709, 219, 738, 227]\n",
      ", - [709, 219, 738, 227]\n",
      "france - [744, 219, 781, 227]\n",
      "33 - [663, 229, 685, 237]\n",
      "- - [663, 229, 685, 237]\n",
      "53 - [690, 230, 713, 238]\n",
      "64 - [713, 230, 733, 238]\n",
      "62 - [734, 230, 751, 238]\n",
      "82 - [751, 229, 774, 239]\n",
      "fa - [354, 256, 387, 271]\n",
      "##x - [354, 256, 387, 271]\n",
      "number - [391, 256, 470, 273]\n",
      ": - [391, 256, 470, 273]\n",
      "305 - [476, 256, 507, 271]\n",
      "400 - [513, 256, 551, 270]\n",
      "- - [513, 256, 551, 270]\n",
      "610 - [554, 256, 602, 273]\n",
      "##7 - [554, 256, 602, 273]\n",
      "kevin - [213, 286, 259, 303]\n",
      "na - [262, 289, 310, 304]\n",
      "##rk - [262, 289, 310, 304]\n",
      "##o - [262, 289, 310, 304]\n",
      "10 - [213, 335, 232, 348]\n",
      "/ - [213, 335, 232, 348]\n",
      "13 - [232, 335, 255, 349]\n",
      "/ - [232, 335, 255, 349]\n",
      "99 - [255, 335, 282, 349]\n",
      "41 - [620, 310, 663, 324]\n",
      "##6 - [620, 310, 663, 324]\n",
      "##2 - [620, 310, 663, 324]\n",
      "/ - [620, 310, 663, 324]\n",
      "158 - [661, 311, 693, 322]\n",
      "please - [326, 372, 376, 387]\n",
      "deliver - [379, 372, 438, 386]\n",
      "as - [442, 374, 460, 385]\n",
      "soon - [462, 373, 503, 386]\n",
      "possible - [527, 370, 594, 384]\n",
      "to - [596, 373, 625, 386]\n",
      ": - [596, 373, 625, 386]\n",
      "john - [143, 430, 181, 447]\n",
      "mu - [185, 432, 255, 449]\n",
      "##lder - [185, 432, 255, 449]\n",
      "##ig - [185, 432, 255, 449]\n",
      "gregory - [144, 458, 209, 476]\n",
      "little - [209, 459, 254, 476]\n",
      "philip - [311, 430, 362, 450]\n",
      "morris - [363, 432, 417, 449]\n",
      "philip - [312, 459, 359, 479]\n",
      "morris - [363, 461, 415, 476]\n",
      "91 - [529, 432, 557, 449]\n",
      "##7 - [529, 432, 557, 449]\n",
      "- - [557, 433, 590, 447]\n",
      "66 - [557, 433, 590, 447]\n",
      "##3 - [557, 433, 590, 447]\n",
      "- - [592, 433, 639, 447]\n",
      "57 - [592, 433, 639, 447]\n",
      "##9 - [592, 433, 639, 447]\n",
      "##6 - [592, 433, 639, 447]\n",
      "91 - [526, 462, 562, 476]\n",
      "##7 - [526, 462, 562, 476]\n",
      "- - [526, 462, 562, 476]\n",
      "66 - [559, 461, 592, 476]\n",
      "##3 - [559, 461, 592, 476]\n",
      "59 - [591, 462, 637, 476]\n",
      "##7 - [591, 462, 637, 476]\n",
      "##9 - [591, 462, 637, 476]\n",
      "91 - [681, 432, 717, 447]\n",
      "##7 - [681, 432, 717, 447]\n",
      "- - [681, 432, 717, 447]\n",
      "66 - [718, 433, 750, 447]\n",
      "##3 - [718, 433, 750, 447]\n",
      "305 - [751, 433, 790, 447]\n",
      "##6 - [751, 433, 790, 447]\n",
      "phone - [681, 404, 741, 419]\n",
      "no - [744, 405, 779, 420]\n",
      ". - [744, 405, 779, 420]\n",
      "total - [316, 497, 358, 511]\n",
      "number - [359, 499, 419, 512]\n",
      "of - [421, 497, 440, 511]\n",
      "pages - [442, 499, 485, 516]\n",
      "including - [486, 497, 558, 514]\n",
      "this - [563, 497, 591, 511]\n",
      "page - [594, 501, 635, 515]\n",
      ": - [594, 501, 635, 515]\n",
      "if - [112, 679, 131, 690]\n",
      "you - [133, 677, 165, 691]\n",
      "do - [168, 680, 188, 691]\n",
      "not - [192, 679, 224, 692]\n",
      "receive - [228, 679, 293, 693]\n",
      "all - [294, 679, 323, 692]\n",
      "the - [327, 679, 359, 692]\n",
      "pages - [359, 680, 413, 694]\n",
      ", - [359, 680, 413, 694]\n",
      "please - [415, 680, 470, 691]\n",
      "call - [474, 682, 513, 692]\n",
      "our - [517, 682, 545, 692]\n",
      "fa - [550, 680, 579, 691]\n",
      "##x - [550, 680, 579, 691]\n",
      "operator - [583, 682, 663, 692]\n",
      "as - [664, 683, 681, 693]\n",
      "soon - [685, 682, 726, 693]\n",
      "as - [729, 682, 748, 693]\n",
      "possible - [750, 682, 822, 693]\n",
      "thank - [424, 694, 480, 707]\n",
      "you - [481, 696, 517, 707]\n",
      ". - [481, 696, 517, 707]\n",
      "312 - [421, 709, 453, 722]\n",
      "- - [421, 709, 453, 722]\n",
      "55 - [456, 709, 485, 722]\n",
      "##8 - [456, 709, 485, 722]\n",
      "- - [456, 709, 485, 722]\n",
      "59 - [486, 709, 518, 722]\n",
      "##48 - [486, 709, 518, 722]\n",
      "the - [131, 821, 153, 835]\n",
      "information - [157, 824, 224, 835]\n",
      "contained - [228, 821, 283, 836]\n",
      "in - [286, 824, 301, 837]\n",
      "this - [305, 824, 323, 835]\n",
      "fa - [326, 824, 376, 835]\n",
      "##cs - [326, 824, 376, 835]\n",
      "##imi - [326, 824, 376, 835]\n",
      "##le - [326, 824, 376, 835]\n",
      "message - [379, 824, 425, 835]\n",
      "is - [429, 824, 444, 834]\n",
      "at - [444, 824, 490, 835]\n",
      "##tor - [444, 824, 490, 835]\n",
      "##ncy - [444, 824, 490, 835]\n",
      "privileged - [494, 824, 550, 835]\n",
      "and - [554, 823, 576, 836]\n",
      "confidential - [579, 824, 645, 837]\n",
      "information - [649, 821, 714, 835]\n",
      "intended - [720, 823, 770, 836]\n",
      "only - [771, 823, 799, 836]\n",
      "for - [803, 821, 818, 835]\n",
      "the - [822, 821, 844, 835]\n",
      "use - [108, 838, 131, 846]\n",
      "of - [135, 837, 145, 847]\n",
      "the - [148, 837, 167, 845]\n",
      "individual - [169, 837, 226, 847]\n",
      "or - [232, 837, 245, 845]\n",
      "entity - [246, 835, 282, 849]\n",
      "named - [283, 835, 322, 848]\n",
      "above - [323, 837, 364, 847]\n",
      ". - [323, 837, 364, 847]\n",
      "if - [364, 835, 375, 849]\n",
      "the - [379, 837, 399, 848]\n",
      "reader - [400, 838, 437, 848]\n",
      "of - [438, 837, 456, 847]\n",
      "this - [456, 835, 476, 846]\n",
      "message - [477, 838, 527, 848]\n",
      "is - [527, 837, 541, 845]\n",
      "not - [542, 838, 562, 846]\n",
      "the - [564, 837, 583, 848]\n",
      "intended - [584, 837, 636, 848]\n",
      "recipient - [639, 838, 689, 848]\n",
      ", - [639, 838, 689, 848]\n",
      "or - [692, 838, 706, 848]\n",
      "the - [710, 838, 729, 849]\n",
      "employee - [732, 838, 789, 849]\n",
      "or - [793, 838, 807, 848]\n",
      "agent - [811, 838, 843, 849]\n",
      "responsible - [108, 848, 173, 859]\n",
      "to - [177, 849, 190, 857]\n",
      "deliver - [192, 849, 233, 859]\n",
      "it - [234, 849, 245, 859]\n",
      "to - [250, 851, 259, 858]\n",
      "the - [265, 848, 279, 859]\n",
      "intended - [286, 849, 338, 859]\n",
      "recipient - [336, 849, 391, 860]\n",
      ", - [336, 849, 391, 860]\n",
      "you - [391, 849, 419, 860]\n",
      "are - [420, 851, 440, 862]\n",
      "here - [442, 848, 484, 861]\n",
      "##by - [442, 848, 484, 861]\n",
      "notified - [484, 848, 531, 861]\n",
      "that - [531, 848, 551, 861]\n",
      "any - [555, 852, 578, 863]\n",
      "dissemination - [579, 849, 660, 862]\n",
      ", - [579, 849, 660, 862]\n",
      "distribution - [667, 848, 732, 862]\n",
      "or - [734, 849, 749, 859]\n",
      "copying - [753, 849, 795, 860]\n",
      "this - [818, 851, 847, 859]\n",
      "communication - [111, 862, 198, 872]\n",
      "strictly - [214, 862, 253, 873]\n",
      "prohibited - [257, 860, 322, 871]\n",
      ". - [257, 860, 322, 871]\n",
      "if - [133, 883, 143, 893]\n",
      "you - [145, 884, 165, 894]\n",
      "have - [168, 883, 196, 893]\n",
      "received - [200, 883, 248, 893]\n",
      "this - [251, 883, 275, 893]\n",
      "communication - [274, 883, 363, 894]\n",
      "in - [367, 881, 380, 891]\n",
      "error - [381, 883, 413, 894]\n",
      ", - [381, 883, 413, 894]\n",
      "please - [416, 883, 452, 893]\n",
      "immediately - [456, 883, 525, 894]\n",
      "not - [527, 883, 561, 896]\n",
      "##ify - [527, 883, 561, 896]\n",
      "us - [566, 884, 576, 892]\n",
      "by - [582, 883, 596, 894]\n",
      "telephone - [598, 881, 659, 894]\n",
      ", - [598, 881, 659, 894]\n",
      "and - [661, 883, 684, 894]\n",
      "return - [683, 884, 718, 894]\n",
      "the - [722, 883, 741, 893]\n",
      "original - [744, 883, 789, 896]\n",
      "message - [793, 884, 843, 895]\n",
      "to - [111, 894, 122, 907]\n",
      "us - [125, 898, 139, 905]\n",
      "at - [140, 895, 153, 905]\n",
      "the - [155, 895, 172, 905]\n",
      "above - [176, 895, 209, 906]\n",
      "address - [213, 897, 255, 905]\n",
      "via - [259, 897, 278, 905]\n",
      "the - [279, 895, 298, 905]\n",
      "u - [299, 894, 312, 905]\n",
      ". - [299, 894, 312, 905]\n",
      "s - [312, 894, 327, 907]\n",
      ". - [312, 894, 327, 907]\n",
      "postal - [330, 895, 366, 905]\n",
      "service - [367, 894, 412, 907]\n",
      ". - [367, 894, 412, 907]\n",
      "thank - [416, 894, 453, 907]\n",
      "you - [456, 897, 480, 908]\n",
      ". - [456, 897, 480, 908]\n",
      "operator - [139, 920, 208, 935]\n",
      "initials - [210, 919, 270, 934]\n",
      ": - [210, 919, 270, 934]\n",
      "[SEP] - [1000, 1000, 1000, 1000]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n",
      "[PAD] - [0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "words = [tokenizer.ids_to_tokens[idx] for idx in input_ids.tolist()]\n",
    "for w,b in zip(words, bboxes):\n",
    "    print(f'{w} - {b.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100,   12, -100, -100,   12, -100,   12, -100,   12, -100, -100,   12,\n",
       "          12,   12, -100,   12, -100,   12,   12, -100,   12, -100,   12,   11,\n",
       "        -100,    9, -100, -100, -100, -100, -100,    1,    7,    4, -100,    1,\n",
       "        -100,    7,    4,    9, -100,    9,    9, -100,    9,    9,    9,    9,\n",
       "           9, -100,    9,    9,    9, -100, -100,    9,    9, -100,    9,    9,\n",
       "        -100,    0, -100, -100,    6,    6,    3,    9,    9,    9,    9, -100,\n",
       "        -100,    9,    9, -100,    9, -100, -100,    9,    9, -100, -100, -100,\n",
       "           9,    9, -100,    9,    9,    9, -100, -100,    9,    9, -100,    9,\n",
       "        -100,    9,    9, -100,    9, -100,    9,    9,    9, -100,    9, -100,\n",
       "           9,    9, -100,    9, -100,    9, -100,    9, -100,    9,    9,    9,\n",
       "           9,    9,    9, -100,    9,    9, -100,    9,    9,    9,    9,    2,\n",
       "        -100,    5, -100,    0,    6, -100,    3, -100,    0,    3, -100, -100,\n",
       "           0, -100,    6, -100,    3,    0, -100, -100, -100,    3,    1,    7,\n",
       "           7,    7,    7,    4, -100,    0,    3, -100, -100,    0,    3,    0,\n",
       "           3,    0,    3,    0, -100,    6, -100, -100,    3, -100, -100, -100,\n",
       "           0, -100, -100,    6, -100,    3, -100, -100,    0, -100, -100,    6,\n",
       "        -100,    3, -100,    2,    5, -100,    2,    8,    8,    8,    8,    8,\n",
       "           5, -100,    9,    9,    9,    9,    9,    9,    9,    9, -100,    9,\n",
       "           9,    9,    9, -100,    9,    9,    9,    9,    9,    9,    9, -100,\n",
       "           9, -100,    9, -100, -100,    9, -100,    9,    9,    9,    9,    9,\n",
       "           9, -100, -100, -100,    9,    9,    9, -100, -100,    9,    9,    9,\n",
       "           9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,\n",
       "           9, -100,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,\n",
       "           9, -100,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,\n",
       "           9,    9,    9, -100,    9,    9,    9, -100,    9,    9,    9,    9,\n",
       "        -100,    9,    9,    9,    9,    9,    9,    9, -100,    9,    9,    9,\n",
       "           9,    9,    9,    9,    9, -100,    9,    9,    9, -100,    9,    9,\n",
       "           9, -100,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,\n",
       "           9,    9,    9,    9, -100,    9, -100,    9,    9, -100,    9,    9,\n",
       "        -100,    2,    5, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0],\n",
       "        [127, 177, 156, 192],\n",
       "        [127, 177, 156, 192],\n",
       "        ...,\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('dlearn': conda)",
   "language": "python",
   "name": "python36864bitdlearnconda54b2ea4882264d059af3c47949da46dc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
